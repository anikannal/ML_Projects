{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\">Introduction</a></span></li><li><span><a href=\"#Why-Random-Forest?\" data-toc-modified-id=\"Why-Random-Forest?-2\">Why Random Forest?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Advantages\" data-toc-modified-id=\"Advantages-2.1\">Advantages</a></span></li><li><span><a href=\"#Disadvantages\" data-toc-modified-id=\"Disadvantages-2.2\">Disadvantages</a></span></li></ul></li><li><span><a href=\"#How-Random-Forest-Works?\" data-toc-modified-id=\"How-Random-Forest-Works?-3\">How Random Forest Works?</a></span></li><li><span><a href=\"#Random-Forests-vs-Decision-Trees\" data-toc-modified-id=\"Random-Forests-vs-Decision-Trees-4\">Random Forests vs Decision Trees</a></span></li><li><span><a href=\"#Project---Flower-Classification-Using-Random-Forest-Algorithm\" data-toc-modified-id=\"Project---Flower-Classification-Using-Random-Forest-Algorithm-5\">Project - Flower Classification Using Random Forest Algorithm</a></span></li><li><span><a href=\"#Data-Load-and-Initial-Exploration\" data-toc-modified-id=\"Data-Load-and-Initial-Exploration-6\">Data Load and Initial Exploration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Changing-Data-Format\" data-toc-modified-id=\"Changing-Data-Format-6.1\">Changing Data Format</a></span></li></ul></li><li><span><a href=\"#Data-Pre-processing\" data-toc-modified-id=\"Data-Pre-processing-7\">Data Pre-processing</a></span></li><li><span><a href=\"#Train-the-Model-and-Predict\" data-toc-modified-id=\"Train-the-Model-and-Predict-8\">Train the Model and Predict</a></span></li><li><span><a href=\"#Evaluate-the-Model\" data-toc-modified-id=\"Evaluate-the-Model-9\">Evaluate the Model</a></span></li><li><span><a href=\"#Hyperparameter-Tuning\" data-toc-modified-id=\"Hyperparameter-Tuning-10\">Hyperparameter Tuning</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Random forest is a supervised learning algorithm. The \"forest\" it builds, is an collection of decision trees, usually trained with the “bagging” method. The general idea of the bagging method is that a combination of learning models increases the overall result.\n",
    "\n",
    "i.e. random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction.\n",
    "\n",
    "It is one of the most used algorithms, because of its simplicity and diversity (it can be used for both classification and regression tasks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Random Forest?\n",
    "\n",
    "Why go to the trouble of creating a forest of decision trees when a single decision tree already works? \n",
    "\n",
    "Trees are easy to build, easy to use, and easy to interpret BUT they are not very accurate. Decision Trees have some intrinsic limitations that a Random Forest helps to address - Decision Trees are prone to overfitting - i.e. they work great with training data but their accuracy is not so great with classifying new samples.\n",
    "\n",
    "Random Forests combine the simplicity of Decision Trees with flexibility to deliver a vast improvement in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages\n",
    "\n",
    "- Random forests is considered as a highly accurate and robust method because of the number of decision trees participating in the process.\n",
    "- It does not suffer from the overfitting problem. The main reason is that it takes the average of all the predictions, which cancels out the biases.\n",
    "- The algorithm can be used in both classification and regression problems.\n",
    "- Random forests can also handle missing values. There are two ways to handle these: using median values to replace continuous variables, and computing the proximity-weighted average of missing values.\n",
    "- You can get the relative feature importance, which helps in selecting the most contributing features for the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages\n",
    "\n",
    "- Random forests is slow in generating predictions because it has multiple decision trees. Whenever it makes a prediction, all the trees in the forest have to make a prediction for the same given input and then perform voting on it. This whole process is time-consuming.\n",
    "- The model is difficult to interpret compared to a decision tree, where you can easily make a decision by following the path in the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Random Forest Works?\n",
    "\n",
    "Here's a short video on how to build a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"814\"\n",
       "            height=\"509\"\n",
       "            src=\"https://www.youtube.com/embed/J4Wdy0Wc_xQ\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa575cf1a50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run this cell (shift+enter) to see the video\n",
    "\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"https://www.youtube.com/embed/J4Wdy0Wc_xQ\", width=\"814\", height=\"509\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests vs Decision Trees\n",
    "- Random forests is a set of multiple decision trees.\n",
    "- Deep decision trees may suffer from overfitting, but random forests prevents overfitting by creating trees on random subsets.\n",
    "- Decision trees are computationally faster.\n",
    "- Random forests is difficult to interpret, while a decision tree is easily interpretable and can be converted to rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project - Flower Classification Using Random Forest Algorithm\n",
    "\n",
    "You will be building a model on the iris flower dataset, which is a very famous classification set. It comprises the sepal length, sepal width, petal length, petal width, and type of flowers. There are three species or classes: setosa, versicolor, and virginia. You will build a model to classify the type of flower. The dataset is available in the scikit-learn library or you can download it from the UCI Machine Learning Repository.\n",
    "\n",
    "Here's a link to the dataset if you wish to explore it further - http://archive.ics.uci.edu/ml/datasets/Iris/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load and Initial Exploration\n",
    "\n",
    "The Iris dataset come preloaded in the scikitlearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the features of our dataset and the different flower types that the samples are classified into - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# print the names of the four features\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# print the label species(setosa, versicolor,virginica)\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Data Format\n",
    "\n",
    "The `iris` object that holds our dataset is not a pandas dataframe. Let's store the data in a dataframe to enable further analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting to a dataframe\n",
    "\n",
    "data=pd.DataFrame({\n",
    "    'sepal length':iris.data[:,0],\n",
    "    'sepal width':iris.data[:,1],\n",
    "    'petal length':iris.data[:,2],\n",
    "    'petal width':iris.data[:,3],\n",
    "    'species':iris.target\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the data before we move ahead - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fac680de990>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fac680f1850>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fac68121410>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fac6815b4d0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fac6818d150>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fac68304510>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "We will not need to do much pre-processing in this case. The data is already in the form we need it. We will do two quick things though - \n",
    "\n",
    "- split the features and the labels\n",
    "- split the data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=data[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Features\n",
    "y=data['species']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test scores for the test dataset - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test scores for the train dataset - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Now that you've built a Random Forest classifier how can you improve the accuracy?\n",
    "\n",
    "We covered Hyperparameter Tuning in the Decision Trees notebook. Let's see how we can apply that to our current project. We will be ranking the importance of features and then selectively use the most important features to re-train our model.\n",
    "\n",
    "The RandomForestClassifier helps us get feature importance scores - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petal length (cm)    0.482035\n",
       "petal width (cm)     0.380779\n",
       "sepal length (cm)    0.108690\n",
       "sepal width (cm)     0.028496\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_,index=iris.feature_names).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the top three features that are pertinent for our model, let's do feature selection accordingly - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into features and labels\n",
    "X=data[['petal length', 'petal width','sepal length']]  # Removed feature \"sepal width\"\n",
    "y=data['species']                                       \n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=5) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrain our model - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# prediction on test set\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and now for the evaluation. Did the feature selection lead to a favorable outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! As you might notice, our accuracy has gone up from 0.933 to 0.952."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This project was created using a variety of online resources as references. This informative tutorial by Vishal Navlani was used extensively - https://www.datacamp.com/community/tutorials/random-forests-classifier-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
